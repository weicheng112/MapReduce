syntax = "proto3";

package dfs;

option go_package = "./proto";

// Message for heartbeat from storage node to controller
message Heartbeat {
  string node_id = 1;
  string node_hostname = 2;
  uint64 free_space = 3;  // Available space in bytes
  
  uint64 requests_processed = 4;
  repeated string new_files = 5;  // Optional: new files stored since last heartbeat
}

// Message for storage request from client to controller
message StorageRequest {
  string filename = 1;
  uint64 file_size = 2;
  uint32 chunk_size = 3;  // Size of each chunk in bytes
}

// Message for storage response from controller to client
message StorageResponse {
  repeated ChunkPlacement chunk_placements = 1;
  string error = 2;  // Empty if successful
}

// Defines where to store a chunk and its replicas
message ChunkPlacement {
  uint32 chunk_number = 1;
  repeated string storage_nodes = 2;  // List of node IDs to store replicas
}

// Message for retrieval request from client to controller
message RetrievalRequest {
  string filename = 1;
}

// Message for retrieval response from controller to client
message RetrievalResponse {
  repeated ChunkLocation chunks = 1;
  string error = 2;  // Empty if successful
}

// Defines where to find a chunk and its replicas
message ChunkLocation {
  uint32 chunk_number = 1;
  repeated string storage_nodes = 2;  // List of node IDs that have the chunk
}

// Message for file deletion request
message DeleteRequest {
  string filename = 1;
}

// Message for file deletion response
message DeleteResponse {
  bool success = 1;
  string error = 2;  // Empty if successful
}

// Message for listing files request
message ListFilesRequest {}

// Message for listing files response
message ListFilesResponse {
  repeated FileInfo files = 1;
}

// File information
message FileInfo {
  string filename = 1;
  uint64 size = 2;
  uint32 num_chunks = 3;
}

// Message for node status request
message NodeStatusRequest {}

// Message for node status response
message NodeStatusResponse {
  repeated NodeInfo nodes = 1;
  uint64 total_space = 2;  // Total available space in cluster (bytes)
}

// Node information
message NodeInfo {
  string node_id = 1;
  uint64 free_space = 2;
  uint64 requests_processed = 3;
}

// Message for chunk storage request to storage node
message ChunkStoreRequest {
  string filename = 1;
  uint32 chunk_number = 2;
  bytes data = 3;
  repeated string replica_nodes = 4;  // Nodes to forward replicas to
}

// Message for chunk storage response from storage node
message ChunkStoreResponse {
  bool success = 1;
  string error = 2;  // Empty if successful
}

// Message for chunk retrieval request to storage node
message ChunkRetrieveRequest {
  string filename = 1;
  uint32 chunk_number = 2;
}

// Message for chunk retrieval response from storage node
message ChunkRetrieveResponse {
  bytes data = 1;
  bool corrupted = 2;
  string error = 3;  // Empty if successful
}

// MapReduce Protocol Messages

// Message for submitting a MapReduce job
message JobSubmitRequest {
  string job_id = 1;           // Unique identifier for the job
  string input_file = 2;       // Input file in DFS
  string output_file = 3;      // Output file in DFS
  bytes job_binary = 4;        // Compiled job binary (plugin or executable)
  uint32 num_reducers = 5;     // Number of reducers to use
  bool is_text_file = 6;       // Whether the input file is text-based (for line-based partitioning)
}

// Response to job submission
message JobSubmitResponse {
  bool success = 1;
  string job_id = 2;           // Job ID assigned by the system
  string error = 3;            // Error message if submission failed
}

// Message for checking job status
message JobStatusRequest {
  string job_id = 1;
}

// Response with job status
message JobStatusResponse {
  enum JobState {
    PENDING = 0;
    MAPPING = 1;
    SHUFFLING = 2;
    REDUCING = 3;
    COMPLETED = 4;
    FAILED = 5;
  }
  
  string job_id = 1;
  JobState state = 2;
  uint32 total_map_tasks = 3;
  uint32 completed_map_tasks = 4;
  uint32 total_reduce_tasks = 5;
  uint32 completed_reduce_tasks = 6;
  string error = 7;            // Error message if job failed
}

// Message for assigning a map task to a storage node
message MapTaskRequest {
  string job_id = 1;
  string task_id = 2;          // Unique identifier for this task
  string filename = 3;
  uint32 chunk_number = 4;
  bytes job_binary = 5;        // Compiled job binary
  repeated ReducerInfo reducers = 6; // Information about reducers for the shuffle phase
}

// Information about a reducer
message ReducerInfo {
  string node_id = 1;
  string address = 2;
  uint32 reducer_number = 3;
}

// Response from a storage node after completing a map task
message MapTaskResponse {
  string job_id = 1;
  string task_id = 2;
  bool success = 3;
  string error = 4;            // Error message if task failed
  repeated string intermediate_files = 5; // Files created during map phase
}

// Message for sending shuffle data to a reducer
message ShuffleRequest {
  string job_id = 1;
  string mapper_id = 2;        // ID of the mapper that generated this data
  uint32 reducer_number = 3;
  repeated KeyValuePair key_value_pairs = 4;
}

// Key-value pair for shuffle phase
message KeyValuePair {
  bytes key = 1;
  bytes value = 2;
}

// Response after receiving shuffle data
message ShuffleResponse {
  string job_id = 1;
  bool success = 2;
  string error = 3;
}

// Message for assigning a reduce task to a storage node
message ReduceTaskRequest {
  string job_id = 1;
  string task_id = 2;
  uint32 reducer_number = 3;
  bytes job_binary = 4;
  string output_file = 5;      // Final output file in DFS
}

// Response from a storage node after completing a reduce task
message ReduceTaskResponse {
  string job_id = 1;
  string task_id = 2;
  bool success = 3;
  string error = 4;
  string output_file = 5;      // Final output file stored in DFS
}

// Message for reporting computation node status to computation manager
message ComputeNodeHeartbeat {
  string node_id = 1;
  string node_hostname = 2;
  uint32 cpu_cores = 3;        // Number of CPU cores available
  uint64 memory_available = 4; // Available memory in bytes
  uint32 active_tasks = 5;     // Number of tasks currently running
  repeated string active_job_ids = 6; // IDs of jobs currently running on this node
}